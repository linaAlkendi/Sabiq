import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
import json

# 1. Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
df = pd.read_json("./backend/data/incidentData.json", encoding='utf-8')

# 2. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© (Ù„Ùˆ Ù…ÙˆØ¬ÙˆØ¯Ø©)
if 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¹Ø·Ù„' in df.columns:
    df['ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¹Ø·Ù„'] = pd.to_datetime(df['ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¹Ø·Ù„'])

# 3. Ø¯Ø§Ù„Ø© Ù„ØªØ­ÙˆÙŠÙ„ Ù…Ø¯Ø© Ø§Ù„ØªÙˆÙ‚Ù (Ù…Ø«Ø§Ù„: "2 Ø³Ø§Ø¹Ø©" -> Ø¯Ù‚Ø§Ø¦Ù‚)
def convert_duration(text):
    try:
        parts = text.strip().split()
        number = float(parts[0].replace(',', '.'))  # Ø¯Ø¹Ù… Ù„Ù„ÙØ§ØµÙ„Ø©
        if "Ø¯Ù‚ÙŠÙ‚Ø©" in parts[1]:
            return number
        elif "Ø³Ø§Ø¹Ø©" in parts[1]:
            return number * 60
        elif "ÙŠÙˆÙ…" in parts[1]:
            return number * 1440
    except:
        return None

df['Ù…Ø¯Ø©_Ø§Ù„ØªÙˆÙ‚Ù_Ø¨Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚'] = df['Ù…Ø¯Ø© Ø§Ù„ØªÙˆÙ‚Ù'].apply(convert_duration)

# 4. ØªØ±Ù…ÙŠØ² Ø§Ù„Ù†ØµÙˆØµ (Ù†ÙˆØ¹ Ø§Ù„Ø¹Ø·Ù„ØŒ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø±ÙÙ‚)
le_type = LabelEncoder()
le_facility = LabelEncoder()

df['Ù†ÙˆØ¹_Ø§Ù„Ø¹Ø·Ù„_Ù…Ø´ÙØ±'] = le_type.fit_transform(df['Ù†ÙˆØ¹ Ø§Ù„Ø¹Ø·Ù„'])
df['Ù†ÙˆØ¹_Ø§Ù„Ù…Ø±ÙÙ‚_Ù…Ø´ÙØ±'] = le_facility.fit_transform(df['Ù†ÙˆØ¹ Ø§Ù„Ù…Ø±ÙÙ‚'])

# 5. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù†Ø§Ù‚ØµØ© ÙÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ù‡Ù…Ø©)
features = ['Ù†ÙˆØ¹_Ø§Ù„Ø¹Ø·Ù„_Ù…Ø´ÙØ±', 'Ù…Ø¯Ø©_Ø§Ù„ØªÙˆÙ‚Ù_Ø¨Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚']
df_clean = df.dropna(subset=features + ['Ù†ÙˆØ¹_Ø§Ù„Ù…Ø±ÙÙ‚_Ù…Ø´ÙØ±'])

X = df_clean[features]
y = df_clean['Ù†ÙˆØ¹_Ø§Ù„Ù…Ø±ÙÙ‚_Ù…Ø´ÙØ±']

# 6. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# 7. ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø§Ø®ØªÙŠØ§Ø±ÙŠØŒ Ù„Ù„Ø·Ø¨Ø§Ø¹Ø©)
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred, target_names=le_facility.classes_))

# 8. ØªÙ†Ø¨Ø¤ Ù…Ø«Ø§Ù„ (ØªØºÙŠÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ø¬Ø©)
example_type_encoded = le_type.transform(['ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ'])[0]  # Ù…Ø«Ø§Ù„
example_duration = 120  # 120 Ø¯Ù‚ÙŠÙ‚Ø© = Ø³Ø§Ø¹ØªÙŠÙ†

example_df = pd.DataFrame({
    'Ù†ÙˆØ¹_Ø§Ù„Ø¹Ø·Ù„_Ù…Ø´ÙØ±': [example_type_encoded],
    'Ù…Ø¯Ø©_Ø§Ù„ØªÙˆÙ‚Ù_Ø¨Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚': [example_duration]
})

predicted_facility_encoded = model.predict(example_df)[0]
predicted_facility = le_facility.inverse_transform([predicted_facility_encoded])[0]

print(f"ğŸ”® Ø§Ù„ØªÙ†Ø¨Ø¤: Ù…Ù† Ø§Ù„Ù…Ø­ØªÙ…Ù„ Ø£Ù† ÙŠØ­ØµÙ„ Ø§Ù„Ø¹Ø·Ù„ Ø§Ù„ØªØ§Ù„ÙŠ ÙÙŠ Ø§Ù„Ù…Ø±ÙÙ‚: {predicted_facility}")

# 9. Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù…Ù„Ù JSON Ù„Ø¹Ø±Ø¶Ù‡Ø§ Ø¨Ø§Ù„ØµÙØ­Ø©
result = {
    "prediction": predicted_facility,
    "summary": df_clean.groupby('Ù†ÙˆØ¹ Ø§Ù„Ø¹Ø·Ù„')['Ù…Ø¯Ø©_Ø§Ù„ØªÙˆÙ‚Ù_Ø¨Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚'].mean().round(2).to_dict()
}

with open('./backend/data/output.json', 'w', encoding='utf-8') as f:
    json.dump(result, f, ensure_ascii=False, indent=2)

print("ØªÙ… Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤ ÙÙŠ Ù…Ù„Ù output.json")
